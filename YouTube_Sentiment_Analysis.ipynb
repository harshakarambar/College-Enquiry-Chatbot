{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUCXXhxNo4QXjJfK4avuif",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshakarambar/College-Enquiry-Chatbot/blob/main/YouTube_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gani2xHZvYoS",
        "outputId": "a6528984-72e6-463d-b3e2-5382c8de8177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”‘ Paste your API key below\n",
        "api_key = 'AIzaSyAOz7RqDKZYAgQaHhcG1DJCIjDk8D5mhvc'\n",
        "video_id = 'dQw4w9WgXcQ'  # Replace with any YouTube video ID\n",
        "\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "def get_comments(video_id, max_results=100):\n",
        "    comments = []\n",
        "    response = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        maxResults=max_results,\n",
        "        textFormat=\"plainText\"\n",
        "    ).execute()\n",
        "\n",
        "    for item in response['items']:\n",
        "        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "        comments.append(comment)\n",
        "    return comments\n",
        "\n",
        "comments = get_comments(video_id)\n",
        "print(\"Fetched\", len(comments), \"comments\")\n"
      ],
      "metadata": {
        "id": "pfPOp3z0vbqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered = [w for w in words if w not in stop_words]\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "cleaned_comments = [clean_text(comment) for comment in comments]\n"
      ],
      "metadata": {
        "id": "ngINSQAuvfXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(text):\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif polarity < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "results = [(original, get_sentiment(cleaned)) for original, cleaned in zip(comments, cleaned_comments)]\n",
        "\n",
        "df = pd.DataFrame(results, columns=[\"Original Comment\", \"Sentiment\"])\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "uwnI0MnUviCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='Sentiment', data=df)\n",
        "plt.title(\"Sentiment Distribution of YouTube Comments\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JEMr_SBtvkRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = \" \".join(cleaned_comments)\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Word Cloud of Cleaned Comments\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c4r3SVktvmw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"YouTube_Sentiment_Results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "QEyDooY3vo-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvBEkZ4mvrvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}